{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission\n",
    "## Please fill out:\n",
    "\n",
    "* Student name: Nastaran Nazemian\n",
    "* Student pace: part time\n",
    "* Scheduled project review date/time: 10/19/2020 11:00PM (PS)\n",
    "* Instructor name: Lindsey Berlin\n",
    "* Blog post URL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Recommending people to buy what they think they need or near to what they used to use in past is one of the most effective way to encourage people to buy more. A recommender system, or a recommendation system is one of the ways that seeks to predict the \"rating\" or \"preference\" a user would give to an item.\n",
    "\n",
    "This thickness is utilized in a variety of areas such as playlist generators for video and music services like MovieLens, that helps you find movies you will like. Rate movies to build a custom taste profile, then MovieLens recommends other movies for you to watch.\n",
    "\n",
    "The dataset that I have used in this project is from a movie recommendation service, MovieLens. This dataset contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SparkSessio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-674b55a8f06d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_algorithms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mknns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSessio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRegressionEvaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommendation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mALS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SparkSessio'"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# For merging 3 dataframe\n",
    "import re\n",
    "from functools import reduce\n",
    "\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise.prediction_algorithms import knns\n",
    "from surprise.similarities import cosine, msd, pearson\n",
    "from surprise import accuracy\n",
    "from surprise.prediction_algorithms import knns, SVD\n",
    "\n",
    "from pyspark.sql import SparkSessio\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read zip file\n",
    "with zipfile.ZipFile(\"ml-latest-small.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull csv file\n",
    "txtfiles = []\n",
    "for file in glob.glob('C:\\Flatiron\\course-material\\ModuleFourFinalProject\\Recommendation\\ml-latest-small\\*.csv'):\n",
    "    txtfiles.append(file)\n",
    "txtfiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each csv files into a dataframe\n",
    "# links_df = pd.read_csv(\"ml-latest-small/links.csv\")\n",
    "# tags_df = pd.read_csv(\"ml-latest-small/tags.csv\")\n",
    "ratings_df = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
    "movies_df = pd.read_csv(\"ml-latest-small/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print each dataframe and look at the info\n",
    "# print(links_df.info())\n",
    "# links_df.head()\n",
    "# print(tags_df.info())\n",
    "# tags_df.head()\n",
    "print(ratings_df.info())\n",
    "ratings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies_df.info())\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop timestamp columns from ratings and tags\n",
    "#tags_df.drop(columns=['timestamp'], inplace=True)\n",
    "ratings_df.drop(columns=['timestamp'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('links_df:',links_df.shape,' ','columns_name:', links_df.columns)\n",
    "# print('tags_df:', tags_df.shape,' ','columns_name:', tags_df.columns)\n",
    "print('ratings_df:', ratings_df.shape,' ','columns_name:',ratings_df.columns)\n",
    "print('movies_df:', movies_df.shape,' ','columns_name:',movies_df.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the dataframes \n",
    "df = pd.merge(movies_df, ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.genres !='(no genres listed)'] \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions \n",
    "#import re\n",
    "p = re.compile(\"([0-9]{4})\")\n",
    "def Movie_Year(title_str):\n",
    "    result = p.search(title_str)\n",
    "    if result:\n",
    "        a = float(result.group())\n",
    "    else:\n",
    "        a = float(\"nan\")\n",
    "    return a\n",
    "\n",
    "l = re.compile(\"([a-zA-Z, ]*)\")\n",
    "def Title_NoYear(title_str):\n",
    "    result = p.search(title_str)\n",
    "    if result:\n",
    "        result1 = l.search(title_str)\n",
    "        a = result1.group(1)\n",
    "    else:\n",
    "        a = title_str\n",
    "    return a\n",
    "\n",
    "def plot_func(title,x_axes, y_axes,data_df, color ):\n",
    "    f, ax = plt.subplots(figsize=(20,10))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    ax.set_title(title, y=1.2, fontsize=20, ha='center').set_position([0.5,1.08])\n",
    "    ax = sns.barplot(x=x_axes, y=y_axes , data= data_df, palette=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] =list(map(lambda x: Movie_Year(x), df.title))\n",
    "df['year'] = df['year'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_year_title'] =list(map(lambda x: Title_NoYear(x), df.title))\n",
    "df['no_year_title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.no_year_title !='']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.year.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.sort_values(ascending=True).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df = df.loc[(df.year >1899) & (df.year < 2020)]\n",
    "year_df.year.sort_values().unique()\n",
    "len(year_df.year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_year = year_df.groupby('year').agg({'year': 'count'})\n",
    "df_movie_year.rename(columns={'year': 'year_count'}, inplace = True)\n",
    "df_movie_year = df_movie_year.reset_index()\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# # Plot the responses for different events and regions\n",
    "ax =sns.lineplot(x=\"year\", y=\"year_count\", data=df_movie_year)\n",
    "ax.set_title(\"Number of Movies Released per Year\", y=1.2, fontsize=20, ha='center').set_position([0.5,1.08])\n",
    "ax.set_ylabel('Number of movies released')\n",
    "ax.set_xlabel('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the a movie genres\n",
    "df1 = df.copy()\n",
    "df1['genres'] = df['genres'].str.split('|')\n",
    "\n",
    "#creat a flattent dataframe\n",
    "flatten_df = df1['genres'].apply(pd.Series) \\\n",
    "        .merge(df, right_index = True, left_index = True) \\\n",
    "        .drop(['genres'], axis = 1) \\\n",
    "        .melt(id_vars = df.columns.drop('genres'), value_name = \"genres\") \\\n",
    "        .drop(\"variable\", axis = 1) \\\n",
    "        .dropna(subset=['genres'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_df.genres.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten_df = flatten_df.loc[flatten_df.genres !='(no genres listed)']\n",
    " flatten_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_df = flatten_df.loc[(flatten_df.year >1899) & (flatten_df.year < 2020)]\n",
    "genres_df = flatten_df.groupby('genres').agg({'genres': 'count'})\n",
    "genres_df['percentage'] = round(genres_df['genres'] * 100 / df.shape[0],2)\n",
    "genres_df.rename(columns={'genres': 'genres_count'}, inplace = True)\n",
    "genres_df = genres_df.reset_index()\n",
    "genres_df.sort_values(by='percentage', ascending=False, inplace=True)\n",
    "genres_df.head()\n",
    "plot_func('Genres Bar Chart','genres', 'percentage', genres_df,\"Blues_d\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"dark\")\n",
    "new_df = flatten_df.groupby(['year','genres']).agg({'year': 'count'})\n",
    "new_df.rename(columns={'year': 'year_count'}, inplace = True)\n",
    "new_df = new_df.reset_index()\n",
    "# Plot each year's time series in its own facet\n",
    "g = sns.relplot(\n",
    "    data=new_df,\n",
    "    x=\"year\", y=\"year_count\", col=\"genres\",hue=\"genres\", \n",
    "    kind=\"line\", palette=\"crest\", linewidth=4, zorder=5,\n",
    "    col_wrap=3, height=2, aspect=1.5, legend=False,\n",
    ")\n",
    "\n",
    "# Iterate over each subplot to customize further\n",
    "for year, ax in g.axes_dict.items():\n",
    "\n",
    "    # Add the title as an annotation within the plot\n",
    "    #ax.text(.8, .85, year, transform=ax.transAxes, fontweight=\"bold\")\n",
    "\n",
    "    # Plot every year's time series in the background\n",
    "    sns.lineplot(\n",
    "        data=new_df, x=\"year\", y=\"year_count\", \n",
    "        estimator=None, color=\".7\", linewidth=1, ax=ax,\n",
    "    )\n",
    "\n",
    "# Reduce the frequency of the x axis ticks\n",
    "ax.set_xticks(ax.get_xticks()[::2])\n",
    "\n",
    "# Tweak the supporting aspects of the plot\n",
    "#g.ax.set_title(\"Yearly Movie Production count by Genrea \")\n",
    "g.set_axis_labels(\"\", 'Number of Movies')\n",
    "g.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_rating_df = flatten_df.groupby(['genres','rating']).agg({'movieId': 'count'})\n",
    "ave_rating_df = ave_rating_df.reset_index()\n",
    "ave_rating_df.sort_values(by='movieId', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "chart = sns.scatterplot(ave_rating_df.genres, ave_rating_df.movieId, hue=ave_rating_df.rating)\n",
    "\n",
    "plt.setp(chart.get_xticklabels(), rotation=45)\n",
    "chart.set_title(\"Rating Count per Genrea\", y=1.2, fontsize=16, ha='center').set_position([0.5,1.08])\n",
    "ax.set_ylabel('Number of Movies released')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df.groupby('title').agg({'rating': 'count'}).sort_values(by='rating', ascending=False)\n",
    "df_title = df_title.reset_index()\n",
    "plot_func('Average Rating per Movies','title', 'rating', df_title[:6], 'Set2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title.title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = df.groupby('rating').agg({'movieId': 'count'}).sort_values(by='rating', ascending=False)\n",
    "df_rating = df_rating.reset_index()\n",
    "plot_func(' Movie Count per Rating','rating', 'movieId', df_rating[:6],'Set3' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings_df, reader)\n",
    "dataset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataset.n_users)\n",
    "print(dataset.n_items)\n",
    "print(dataset.n_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.1)\n",
    "print(len(testset))\n",
    "print(testset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of users: ', trainset.n_users, '\\n')\n",
    "print('Number of items: ', trainset.n_items, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_cos = {'name':'cosine', 'user_based':False}\n",
    "basic = knns.KNNBasic(sim_options=sim_cos)\n",
    "basic.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic.sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = basic.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(n_factors=20, n_epochs=10, lr_all=0.0005, reg_all=0.4)\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate SparkSession object\n",
    "# spark = SparkSession.builder.master('local').getOrCreate()\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('ALSExample').config('spark.driver.host', 'localhost')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = spark.read.csv('C:/Flatiron/course-material/ModuleFourFinalProject/Recommendation/ml-latest-small/ratings.csv', header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = movie_ratings.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "(training, test) = movie_ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5,rank=4, regParam=0.01, userCol='userId', itemCol='movieId', ratingCol='rating',\n",
    "          coldStartStrategy='drop')\n",
    "\n",
    "# fit the ALS model to the training set\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing appropriate library\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Root-mean-square error = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# initialize the ALS model\n",
    "als_model = ALS(userCol='userId', itemCol='movieId', \n",
    "                ratingCol='rating', coldStartStrategy='drop')\n",
    "\n",
    "# create the parameter grid                 \n",
    "params = ParamGridBuilder()\\\n",
    "          .addGrid(als_model.regParam, [0.01, 0.001, 0.1])\\\n",
    "          .addGrid(als_model.rank, [4, 10, 50]).build()\n",
    "\n",
    "\n",
    "# instantiating crossvalidator estimator\n",
    "cv = CrossValidator(estimator=als_model, estimatorParamMaps=params,evaluator=evaluator,parallelism=4)\n",
    "best_model = cv.fit(movie_ratings)    \n",
    "\n",
    "# We see the best model has a rank of 50, so we will use that in our future models with this dataset\n",
    "best_model.bestModel.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = spark.read.csv('C:/Flatiron/course-material/ModuleFourFinalProject/Recommendation/ml-latest-small/movies.csv',header='true',inferSchema='true')\n",
    "movie_titles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_retriever(movie_id, movie_title_df):\n",
    "    return movie_title_df.where(movie_title_df.movieId == movie_id).take(1)[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name_retriever(1023, movie_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = movie_ratings.select(als.getUserCol()).distinct().limit(1)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "recs = userSubsetRecs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use indexing to obtain the movie id of top predicted rated item\n",
    "first_recommendation = recs[0]['recommendations'][0][0]\n",
    "\n",
    "# use the name retriever function to get the values\n",
    "name_retriever(first_recommendation,movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.recommendForAllUsers(5)\n",
    "recommendations.where(recommendations.userId == 3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_user_recs(user_id, new_ratings, rating_df, movie_title_df, num_recs):\n",
    "    # turn the new_recommendations list into a spark DataFrame\n",
    "    new_user_ratings = spark.createDataFrame(new_ratings,rating_df.columns)\n",
    "    \n",
    "    # combine the new ratings df with the rating_df\n",
    "    movie_ratings_combined = rating_df.union(new_user_ratings)\n",
    "    \n",
    "    # split the dataframe into a train and test set\n",
    "#     (training, test) = movie_ratings_combined.randomSplit([0.8, 0.2],seed=0)\n",
    "    \n",
    "    # create an ALS model and fit it\n",
    "    als = ALS(maxIter=5,rank=50, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "    model = als.fit(movie_ratings_combined)\n",
    "    \n",
    "    # make recommendations for all users using the recommendForAllUsers method\n",
    "    recommendations = model.recommendForAllUsers(num_recs)\n",
    "    \n",
    "    # get recommendations specifically for the new user that has been added to the DataFrame\n",
    "    recs_for_user = recommendations.where(recommendations.userId == user_id).take(1)\n",
    "    \n",
    "    for ranking, (movie_id, rating) in enumerate(recs_for_user[0]['recommendations']):\n",
    "        movie_string = name_retriever(movie_id,movie_title_df)\n",
    "        print('Recommendation {}: {}  | predicted score :{}'.format(ranking+1,movie_string,rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 100000\n",
    "user_ratings_1 = [(user_id,3253,5),\n",
    "                  (user_id,2459,5),\n",
    "                  (user_id,2513,4),\n",
    "                  (user_id,6502,5),\n",
    "                  (user_id,1091,5),\n",
    "                  (user_id,441,4)]\n",
    "new_user_recs(user_id,\n",
    "             new_ratings=user_ratings_1,\n",
    "             rating_df=movie_ratings,\n",
    "             movie_title_df=movie_titles,\n",
    "             num_recs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
